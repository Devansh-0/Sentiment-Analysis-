{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Dmn5D5qwNTSW5dovrcLX5x_TmaD2KKaa",
      "authorship_tag": "ABX9TyNILwsCVRTBwEgWvBfpRaHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devansh-0/Sentiment-Analysis-/blob/main/Sentiment_Analysis_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZfcXV4khWYT"
      },
      "source": [
        " import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "import nltk "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxQ9MurhX96"
      },
      "source": [
        "data_source_url = \"https://raw.githubusercontent.com/kolaveridi/kaggle-Twitter-US-Airline-Sentiment-/master/Tweets.csv\"\n",
        "airline_tweets = pd.read_csv(data_source_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5hozKwFhc1T"
      },
      "source": [
        "airline_tweets.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxwApSuXhigd"
      },
      "source": [
        "features = airline_tweets.iloc[:, 10].values\n",
        "labels = airline_tweets.iloc[:, 1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUOt3XLOhsT7"
      },
      "source": [
        "processed_features = []\n",
        "\n",
        "for sentence in range(0, len(features)):\n",
        " \n",
        "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
        "\n",
        "   \n",
        "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "\n",
        "    \n",
        "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
        "\n",
        "  \n",
        "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
        "\n",
        "   \n",
        "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
        "\n",
        "   \n",
        "    processed_feature = processed_feature.lower()\n",
        "\n",
        "    processed_features.append(processed_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOu-8-aHhviR"
      },
      "source": [
        "! pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoH0j-RpiXa5"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
        "processed_features = vectorizer.fit_transform(processed_features).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEmk0Kzjia6D"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwVfhSn6ihnA"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
        "text_classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jac8fKEimiq"
      },
      "source": [
        "predictions = text_classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHJAAnYSivy0",
        "outputId": "3b72f2d5-6aad-4919-87bd-3d057b0db7c4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1723  108   39]\n",
            " [ 326  248   40]\n",
            " [ 132   58  254]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.92      0.85      1870\n",
            "     neutral       0.60      0.40      0.48       614\n",
            "    positive       0.76      0.57      0.65       444\n",
            "\n",
            "    accuracy                           0.76      2928\n",
            "   macro avg       0.72      0.63      0.66      2928\n",
            "weighted avg       0.75      0.76      0.74      2928\n",
            "\n",
            "0.7599043715846995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91mvUwEEi1dp",
        "outputId": "609ec26e-dc65-48c9-b1f3-c73da2b083eb"
      },
      "source": [
        "!pip intall steamlit\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n",
            "Collecting pyngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/63/e086f165125e9bf2e71c0db2955911baaaa0af8947ab5c7b3771bdf4d4d5/pyngrok-5.0.0.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.0-cp36-none-any.whl size=18780 sha256=197a41db787b28eeec9879460c920df4d934937f585155a2606107e518f2e2f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/df/23/af8dde08c3fcdc7b966adcacef48ab29aa3b0b1860df5d2b79\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFzteurckCY5",
        "outputId": "0df73c25-97f0-4c15-f1d5-455530537e1a"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Sentiment Analysis')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}